# 2023/12/06 
- 更新了自己电脑中所有mlir依赖环境的版本，成功编译mlir
## 相关资料参考
- https://github.com/KEKE046/mlir-tutorial
- https://mlir.llvm.org
- https://github.com/BBuf/tvm_mlir_learn
## TODO
- 有能力和时间再去详细学习mlir的Dialect，官网教程里有Toy语言(命名很有意思)的手把手教学
- 有个可能是做mlir DL编译器相关方面的佬网名是BBuf，知乎里有他的mlir教学，Github上也有tvm_mlir教学，都可以看看

# 2023/12/08
- 使用onnx-mlir开源项目完成.onnx转化为.so
## 相关资料参考
- https://github.com/onnx/onnx-mlir
- https://github.com/minisparrow/run-lenet-onnx-mlir
## 些许牢骚
- onnx-mlir的环境跟个鬼一样，编译的报错匪夷所思，十分诡异的报错
- onnx-mlir的部署环境docker镜像是不允许你交互，你只能在创建容器的时候传入.onnx模型然后产生.so后删除容器，不允许你远程连接，挺有道理的，但刚开始没习惯不允许交互的docker容器
## TODO
- 有心情了再在自己的环境中重新尝试编译onnx-mlir，不想折腾环境了

# 2023/12/11
- 完成了.so和.onnx的推理，同时发现.so在仅仅使用python的multiproccessing的情况下，由于GIL的存在，推理速度还是慢于.onnx
## TODO
- 寻找多核PyRuntime共享库，现在的共享库只能使用单核